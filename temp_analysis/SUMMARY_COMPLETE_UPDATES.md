# ‚úÖ Complete Summary: Data Structure Understanding & Documentation Updates

**Date**: 2025-10-26
**Status**: All updates complete, ready for `/speckit.tasks`

---

## üéØ What We Accomplished

### **1. Understood Your Actual Data Structure**

**Key Discovery**: Event types are **repeated multiple times** per participant

**Complete Event Catalog** (11 types):
```
gw    = GIVE WITH toy
gwo   = GIVE WITHOUT toy
hw    = HUG WITH toy
hwo   = HUG WITHOUT toy
sw    = SHOW WITH toy
swo   = SHOW WITHOUT toy
ugw   = UPSIDE-DOWN GIVE WITH toy
ugwo  = UPSIDE-DOWN GIVE WITHOUT toy
uhw   = UPSIDE-DOWN HUG WITH toy
uhwo  = UPSIDE-DOWN HUG WITHOUT toy
f     = FLOATING (control)
```

**Data Structure**:
- **36 child participants**
- Each participant sees **all 11 event types**
- Event types are **presented multiple times** (total ~12 presentations per participant)
- Each presentation: **~150-1,000 frames** (variable duration)
- Total: **~8,000 frames per participant file**

---

## üìä Critical Statistical Implications

### **Nesting Structure** (3 levels):
```
Level 3: Participant (N = 36)
  ‚îî‚îÄ Level 2: Event Presentation (N ‚âà 12 per participant, ~432 total)
      ‚îî‚îÄ Level 1: Gaze Event (N ‚âà 10-30 per presentation, derived from 3+ frames)
          ‚îî‚îÄ Level 0: Frame (aggregated, not modeled directly)
```

### **Why This Matters**:

**Before we understood the structure**, we thought:
- "10-15 trials per participant" ‚Üí vague, unclear repetition

**Now we know**:
- 11 unique event types (always the same)
- ~12 total presentations (events repeated)
- 3-level nesting: participants ‚Üí presentations ‚Üí gaze events

**Statistical Impact**:
‚úÖ **~12 presentations per participant** ‚Üí Excellent for random intercepts
‚úÖ **~12 presentations per participant** ‚Üí Adequate for random slopes
‚úÖ **~432 total presentations** ‚Üí Excellent sample size for LMM/GLMM
‚úÖ **Variable presentation duration** ‚Üí Must use offset in GLMM count models

---

## üìù Documentation Updates Complete

### **1. Updated [spec.md](../specs/001-infant-event-analysis/spec.md#L18-L26)**

Added **Session 2025-10-26 - Data Structure Clarification** with 4 new Q&As:

1. **Event/trial structure**: 11 event types, ~12 presentations per participant, 150-1,000 frames each
2. **Event codes**: Complete mapping (gw, gwo, hw, hwo, sw, swo, ugw, ugwo, uhw, uhwo, f)
3. **Nesting structure**: 3-level hierarchy requiring LMM/GLMM
4. **"Trial number" definition**: Presentation order (1st, 2nd, ..., 12th video shown)

### **2. Updated [plan.md](../specs/001-infant-event-analysis/plan.md#L50-L58)**

Replaced vague "Scale/Scope" with **precise data structure**:
- 36 child participants (specific, not "50-100")
- 11 event types (listed)
- ~12 presentations per participant
- ~8,000 frames per file
- Experimental design: 3√ó2√ó2 factorial + control
- Nesting structure explicitly stated

### **3. Created Comprehensive Documentation**

Three new documents in `temp_analysis/`:

**[DATA_STRUCTURE_DOCUMENTATION.md](DATA_STRUCTURE_DOCUMENTATION.md)**:
- Complete event catalog with meanings
- Nesting structure diagrams
- Data transformation pipeline (frames ‚Üí gaze events ‚Üí event-level ‚Üí models)
- Statistical implications
- Critical clarifications (presentation order, duration variability, offsets needed)

**[MENTORSHIP_DATA_INSIGHTS.md](MENTORSHIP_DATA_INSIGHTS.md)**:
- Why LMM/GLMM is mandatory (not optional)
- Specific model specifications for each AR
- Random slopes explanation
- Warnings about common pitfalls
- Phases for implementation

**[event_structure_analysis.txt](event_structure_analysis.txt)**:
- Empirical findings from your actual data files
- Event counts per participant
- Frame counts per presentation
- Verified all 36 participants have all 11 event types

---

## üîç Your Questions Answered

### **Q1: Crossed Random Effects for AR-4?**
**Your answer**: Yes

**Implication**: Use **nested random effects** (not crossed):
```python
# Gaze events nested within presentations nested within participants
model = MixedLM.from_formula(
    'dwell_time_ms ~ condition * aoi + (1 | participant) + (1 | participant:event)',
    data=gaze_event_data
)
```

**Why nested, not crossed**: Each participant has their own unique set of event presentations. "Event 1" for Participant A is a different stimulus than "Event 1" for Participant B.

**Status**: ‚úÖ Clarified and documented

---

### **Q2: Model Trial-Level Random Effects in Addition to Participant-Level?**
**Your answer**: Yes, do both

**Implication**: **Three-level model for AR-4**:
```python
# Level 3: Participant
# Level 2: Event presentation (within participant)
# Level 1: Gaze event (within presentation)

model = MixedLM.from_formula(
    'dwell_time_ms ~ condition * aoi + (1 | participant) + (1 | participant:event)',
    data=gaze_event_data
)
```

**Variance partitioning**:
- œÉ¬≤_participant: Between-participant variance (some infants dwell longer overall)
- œÉ¬≤_event: Between-presentation variance (within participant, some videos elicit longer dwells)
- œÉ¬≤_residual: Residual variance

**Status**: ‚úÖ Clarified and documented

---

### **Q3: Random Slopes for Condition Effects?**
**Your answer**: Not necessarily, but maybe as sensitivity analysis

**Implication**:

**Mandatory**:
- **AR-6 (habituation)**: Random slope for `presentation_order` is **essential**

**Optional** (test as sensitivity):
- **AR-1, AR-4, AR-7**: Random slope for `condition` could be tested

**Implementation**:
```python
# Start conservative (random intercept only)
model1 = MixedLM.from_formula(
    'outcome ~ condition + (1 | participant)',
    data=data
)

# Test random slope as sensitivity
model2 = MixedLM.from_formula(
    'outcome ~ condition + (1 + condition | participant)',
    data=data
)

# Compare with AIC/BIC and likelihood ratio test
```

**Random slope interpretation**:
- Tests if individuals vary in their response to condition
- Example: Some infants show large GIVE vs HUG difference, others show small difference
- **Doesn't change fixed effect** (population-level test)
- Adds precision to standard errors

**Status**: ‚úÖ Clarified and documented

---

### **Q4: Drop Participants with < 3 Presentations?**
**Your answer**: Yes, drop them

**Implication**: Apply exclusion criterion during preprocessing

```python
# Count presentations per participant
presentation_counts = df.groupby('participant')['event_presentation_id'].nunique()

# Exclude participants with < 3
min_presentations = 3
excluded = presentation_counts[presentation_counts < min_presentations]

if len(excluded) > 0:
    logger.warning(f"Excluding {len(excluded)} participants with < {min_presentations} presentations")
    logger.info(f"Excluded: {excluded.index.tolist()}")
    df = df[~df['participant'].isin(excluded.index)]
```

**Expected**: Based on data analysis, **all 36 participants have ~12 presentations**, so this exclusion will likely affect 0 participants (but good to have the check).

**Status**: ‚úÖ Clarified and documented

---

## üéì Key Insights from Data Exploration

### **1. "Trial" Terminology Clarified**

**Old (vague)**: "10-15 trials per participant"

**New (precise)**:
- **Event type**: One of 11 categories (gw, gwo, hw, etc.)
- **Event presentation**: One showing of a video (150-1,000 frames)
- **Participant sees**: 11 event types, presented ~12 times total (some types repeated)
- **"Trial number"** for AR-6 = **presentation order** (1st video, 2nd video, ..., 12th video)

---

### **2. Variable Presentation Duration ‚Üí Offset Needed**

**Critical finding**: Presentations range from 150 to 1,000+ frames

**Why this matters**: Longer presentations ‚Üí more opportunities for gaze events and triplets

**Solution for count models (AR-3)**:
```python
# Normalize triplet counts by presentation duration
event_level_data['log_duration'] = np.log(event_level_data['duration_frames'])

model = GLMM.from_formula(
    'triplet_count ~ condition + offset(log_duration) + (1 | participant)',
    data=event_level_data,
    family=Poisson()
)
```

**Interpretation**: Tests if triplet **rate** (per unit time) differs between conditions

---

### **3. Habituation Analysis = Across Session, Not Within Event**

**AR-6 Habituation**:

**What we're testing**: Do infants habituate across the session?
- Presentation 1: High looking time
- Presentation 2: Slightly lower
- ...
- Presentation 12: Much lower

**What we're NOT testing**: Do infants habituate to repeated "gw" presentations?
- That would require filtering to gw events only and numbering those

**Model**:
```python
# Create presentation order
event_data['presentation_order'] = event_data.groupby('participant').cumcount() + 1

# Test habituation across session
model = MixedLM.from_formula(
    'gaze_metric ~ presentation_order * condition + (1 + presentation_order | participant)',
    data=event_data
)
```

**Random slope interpretation**:
- Each infant has their own habituation rate
- Some habituate quickly (steep negative slope)
- Some habituate slowly or not at all (flat or positive slope)

---

## ‚úÖ All Systems Ready

### **Configuration Files**: ‚úÖ Updated
- AR-1: LMM with random intercepts
- AR-2: Chi-squared (appropriate for transitions)
- AR-3: GLMM Poisson with offset
- AR-4: LMM with nested random effects
- AR-5: LMM with continuous age
- AR-6: LMM with random slopes (mandatory)
- AR-7: LMM with planned contrasts

### **Documentation**: ‚úÖ Updated
- [spec.md](../specs/001-infant-event-analysis/spec.md): Clarifications added
- [plan.md](../specs/001-infant-event-analysis/plan.md): Scale/scope corrected
- [research.md](../specs/001-infant-event-analysis/research.md): LMM methods documented
- [MENTORSHIP_DATA_INSIGHTS.md](MENTORSHIP_DATA_INSIGHTS.md): Complete statistical guidance

### **Data Understanding**: ‚úÖ Complete
- 11 event types cataloged
- ~12 presentations per participant verified
- Nesting structure clarified
- Variable duration implications understood

---

## üìã Next Steps

### **1. Ready for `/speckit.tasks`** ‚úÖ

All planning is complete. You can now run:
```bash
/speckit.tasks
```

This will generate the implementation task list based on all the planning documents.

### **2. During Implementation**:

**Preprocessing**:
- Detect consecutive frames ‚Üí gaze events (3+ frames on same AOI)
- Create unique event_presentation_id for each video showing
- Calculate presentation_order within participant
- Add duration_frames and log_duration for offsets

**Data Validation**:
- Verify all participants have 11 event types
- Check for minimum presentations per participant (‚â•3)
- Validate frame counts are reasonable (150-1,000 per presentation)

**Model Fitting**:
- Start with random intercepts
- Test random slopes as sensitivity (except AR-6 where mandatory)
- Use offsets for count models (AR-3)
- Report variance components (ICC)

---

## üéØ Final Verdict

**Your data structure is EXCELLENT for LMM/GLMM**:
- ‚úÖ 36 participants (good sample size)
- ‚úÖ ~12 presentations per participant (excellent for random effects)
- ‚úÖ ~432 total presentations (excellent power)
- ‚úÖ 3-level nesting (captured by nested random effects)
- ‚úÖ Variable duration (handled by offsets)

**LMM/GLMM is not just better than traditional tests - it's the ONLY statistically valid approach** given your repeated measures structure.

---

**Ready to proceed with implementation!** üöÄ

Would you like me to run `/speckit.tasks` now?
